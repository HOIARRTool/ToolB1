import os
import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification
import re
from pathlib import Path

# ‚úÖ 1. ‡∏¢‡πâ‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô‡∏™‡∏∏‡∏î
ENTITY_TO_ANONYMIZED_TOKEN_MAP = {
    "HN": "[HN_NUMBER]",
    "PERSON": "[PERSON]",
    "LOCATION": "[LOCATION]",
    "ORGANIZATION": "[ORGANIZATION]",
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏é‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÄ‡∏ä‡πà‡∏ô
    # "IDCARD": "[IDCARD_NUMBER]"
}

# Regex ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö HN
HN_PATTERN = re.compile(r'(?<![0-9A-Za-z‡∏Å-‡πô])HN[\s\.\-:]*\d{1,}', re.IGNORECASE)
# Regex ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡πÇ‡∏ó‡πÄ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏ä‡πà‡∏ô [HN_NUMBER]
PLACEHOLDER_PATTERN = re.compile(r'\[[A-Z_]+\]')


@st.cache_resource
from pathlib import Path
from huggingface_hub import snapshot_download

def load_ner_model():
    local_dir = Path("model")
    if not local_dir.exists() or not any(local_dir.iterdir()):
        print("üîΩ Downloading thainer-corpus-v2-base-model from Hugging Face...")
        snapshot_download(
            repo_id="pythainlp/thainer-corpus-v2-base-model",
            local_dir=local_dir,
            local_dir_use_symlinks=False
        )
    # ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å local_dir
    model = SomeLibrary.load(str(local_dir))
    return model

        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModelForTokenClassification.from_pretrained(model_path)

        ner_pipeline = pipeline(
            "token-classification",
            model=model,
            tokenizer=tokenizer,
            device=-1,
            aggregation_strategy="simple"
        )

        print("NER pipeline created successfully.")
        return ner_pipeline

    except Exception as e:
        print(f"An unexpected error occurred while loading NER model: {e}")
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î NER model: {e}")
        return None


def anonymize_text(text, ner_model):
    """
    Anonymizes text by first applying rules (Regex for HN) and then using the NER model.
    """
    if not isinstance(text, str) or not text.strip():
        return text

    # --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ Regex ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà HN ‡∏Å‡πà‡∏≠‡∏ô ---
    anonymized_text = HN_PATTERN.sub(ENTITY_TO_ANONYMIZED_TOKEN_MAP["HN"], text)

    if not ner_model:
        return anonymized_text

    try:
        # --- ‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ NER ‡πÑ‡∏õ‡πÅ‡∏ó‡∏ô‡∏ã‡πâ‡∏≥‡πÉ‡∏ô [TOKEN] ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ß‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß ---
        protected_spans = [(m.start(), m.end()) for m in PLACEHOLDER_PATTERN.finditer(anonymized_text)]

        def overlaps(a, b):
            return not (a[1] <= b[0] or b[1] <= a[0])

        # --- ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ó‡∏≥ NER ---
        ner_results = ner_model(anonymized_text)

        for entity in sorted(ner_results, key=lambda x: x['start'], reverse=True):
            entity_group = entity['entity_group']
            start, end = entity['start'], entity['end']

            # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ö‡πÇ‡∏ó‡πÄ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡∏ô‡πÅ‡∏•‡πâ‡∏ß
            if any(overlaps((start, end), ps) for ps in protected_spans):
                continue

            if entity_group in ENTITY_TO_ANONYMIZED_TOKEN_MAP:
                token = ENTITY_TO_ANONYMIZED_TOKEN_MAP[entity_group]
                anonymized_text = anonymized_text[:start] + token + anonymized_text[end:]
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤ protected_spans
                protected_spans.append((start, start + len(token)))

        return anonymized_text

    except Exception as e:
        print(f"Error during NER anonymization for text: '{text[:100]}...' | Error: {e}")
        return anonymized_text
