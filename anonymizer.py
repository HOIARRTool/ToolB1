# anonymizer.py
import re
from pathlib import Path

import streamlit as st
from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification
from huggingface_hub import snapshot_download

# ====== ‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏Å‡∏õ‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ======
ENTITY_TO_ANONYMIZED_TOKEN_MAP = {
    "HN": "[HN_NUMBER]",
    "PERSON": "[PERSON]",
    "LOCATION": "[LOCATION]",
    "ORGANIZATION": "[ORGANIZATION]",
}

# ====== Regex rules ======
HN_PATTERN = re.compile(r'HN[\s\.\-:]*\d+', re.IGNORECASE)
PLACEHOLDER_PATTERN = re.compile(r'\[[A-Z_]+\]')  # ‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏ô‡∏ã‡πâ‡∏≥‡πÉ‡∏ô [TOKEN]


@st.cache_resource
def load_ner_model():
    """
    ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å) ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• NER ‡∏à‡∏≤‡∏Å Hugging Face
    ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏•‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (st.status)
    """
    with st.status("üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• NER...", expanded=True) as status:
        try:
            local_dir = Path("model")
            if not local_dir.exists() or not any(local_dir.iterdir()):
                st.write("üîΩ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Hugging Face...")
                snapshot_download(
                    repo_id="pythainlp/thainer-corpus-v2-base-model",
                    local_dir=local_dir,
                    local_dir_use_symlinks=False,
                )

            st.write("‚öôÔ∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥...")
            tokenizer = AutoTokenizer.from_pretrained(str(local_dir))
            model = AutoModelForTokenClassification.from_pretrained(str(local_dir))

            ner_pipeline = pipeline(
                "token-classification",
                model=model,
                tokenizer=tokenizer,
                device=-1,  # CPU
                aggregation_strategy="simple",
            )
            status.update(label="‚úÖ ‡πÇ‡∏´‡∏•‡∏î NER pipeline ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß", state="complete")
            return ner_pipeline

        except Exception as e:
            status.update(label=f"‚ùå ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}", state="error")
            return None


def anonymize_text(text: str, ner_model):
    """
    ‡∏õ‡∏Å‡∏õ‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: ‡∏ó‡∏≥ Regex HN ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πà‡∏≠‡∏¢‡∏ú‡πà‡∏≤‡∏ô NER
    """
    if not isinstance(text, str) or not text.strip():
        return text

    anonymized = HN_PATTERN.sub(ENTITY_TO_ANONYMIZED_TOKEN_MAP["HN"], text)

    if not ner_model:
        return anonymized

    try:
        protected_spans = [(m.start(), m.end()) for m in PLACEHOLDER_PATTERN.finditer(anonymized)]

        def overlaps(a, b):
            return not (a[1] <= b[0] or b[1] <= a[0])

        ner_results = ner_model(anonymized)

        for ent in sorted(ner_results, key=lambda x: x["start"], reverse=True):
            start, end = ent["start"], ent["end"]
            if any(overlaps((start, end), ps) for ps in protected_spans):
                continue

            group = ent.get("entity_group")
            if group in ENTITY_TO_ANONYMIZED_TOKEN_MAP:
                token = ENTITY_TO_ANONYMIZED_TOKEN_MAP[group]
                anonymized = anonymized[:start] + token + anonymized[end:]
                protected_spans.append((start, start + len(token)))

        return anonymized

    except Exception:
        # ‡∏ñ‡πâ‡∏≤ NER ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ó‡∏≥ Regex ‡πÅ‡∏•‡πâ‡∏ß
        return anonymized


def anonymize_column(df, text_col: str, ner_model, out_col: str = "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏¥‡∏î_Anonymized"):
    """
    ‡∏õ‡∏Å‡∏õ‡∏¥‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÄ‡∏î‡∏µ‡∏¢‡∏ß + progress bar
    """
    if text_col not in df.columns:
        df[out_col] = df.get(text_col, "")
        return df

    with st.status("üîí ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏Å‡∏õ‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‚Ä¶", expanded=True) as status:
        n = len(df)
        pbar = st.progress(0)

        texts = df[text_col].astype(str).tolist()
        out = []
        for i, txt in enumerate(texts, start=1):
            out.append(anonymize_text(txt, ner_model))
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏õ‡πá‡∏ô % ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà
            pbar.progress(int(i * 100 / max(n, 1)))

        df[out_col] = out
        status.update(label="‚úÖ ‡∏õ‡∏Å‡∏õ‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢", state="complete")
        return df
